defaults:
  - optimizer: sgd_cifar10
  - scheduler: step_lr
feature_norm: true
train_batch_size: 128
val_batch_size: 128
test_batch_size: 128
max_epochs: 200

# For CIFAR10 experiments, we use SGD as the optimizer with batch size 128,
# initial learning rate 0.1, Cosine decay scheduler, momentum 0.9, weight decay

seed: 0
str: train_batch_size=${.train_batch_size}-${.optimizer.str}-scheduler=${.scheduler.str}-seed=${.seed}